{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07405dcf",
   "metadata": {},
   "source": [
    "# Implement the forward propagation for a two hidden layer network for m-samples, n-features as we discussed in class. \n",
    "\n",
    "# Initialize the weights randomly. Use the data from the previous labs like logistic regression. \n",
    "\n",
    "# You can choose the number of neurons in the hidden layer and use sigmoid activation function.Report the evaluation metrics for the network.  \n",
    "\n",
    "# Also use other non-linear activation functions like ReLU and Tanh. \n",
    "\n",
    "# Report the loss using both MSE and Cross Entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb23f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np     # importing different libaries\n",
    "import math as m\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e3a8dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_entropy(y, pred_y):    # defining cross entropy loss function.\n",
    "    error = 0\n",
    "    for i in range(y.shape[0]):\n",
    "        if(y[i][0] == 1):\n",
    "            val1 = -(np.log(pred_y[i][0]))\n",
    "            error += val1\n",
    "        else:\n",
    "            val2 = -(np.log(1 - pred_y[i][0]))\n",
    "            error += val2\n",
    "    error = error/y.shape[0]\n",
    "    return error\n",
    "\n",
    "\n",
    "def MSE(y, pred_y):        # defining mean squared error loss function.\n",
    "    error = 0\n",
    "    for i in range(y.shape[0]):\n",
    "        error += (y[i][0] - pred_y[i][0])**2\n",
    "        \n",
    "    error = error/y.shape[0]\n",
    "    return error\n",
    "    \n",
    "\n",
    "def sigmoid(z, diff):       # defining sigmoid function. The argument diff is taken as \n",
    "    val = val = 1/(1 + np.exp(-z))         # the function called for differentiation or not.\n",
    "    if(diff == True):\n",
    "        val = val*(1 - val)\n",
    "    return val\n",
    "\n",
    "def Relu(z, diff):        # defining relu function.\n",
    "    val = np.maximum(0, z)\n",
    "    if(diff == True):\n",
    "        pass\n",
    "    return val\n",
    "\n",
    "def Tanh(z, diff):       # defining tanh function.\n",
    "    val = np.tanh(z)\n",
    "    if(diff == True):\n",
    "        pass\n",
    "    return val\n",
    "\n",
    "def forward_prop(x, n_layer, f_list, w_list, b_list):  # defining forward propagation algorithm.\n",
    "    layer_output_list = []      # This list stores each layer output values.\n",
    "    activation_list = []       # This list stores pre-activation values.\n",
    "    \n",
    "    h = x\n",
    "    for i in range(n_layer - 1):\n",
    "        active = np.dot(w_list[i], h) + b_list[i]\n",
    "        activation_list.append(active)\n",
    "        output = f_list[i](active, diff = False)\n",
    "        layer_output_list.append(output)\n",
    "        h = output\n",
    "        \n",
    "    active = np.dot(w_list[n_layer - 1], h) + b_list[n_layer - 1]\n",
    "    activation_list.append(active)   \n",
    "    output = f_list[n_layer - 1](active, diff = False)\n",
    "    layer_output_list.append(output)\n",
    "        \n",
    "    return activation_list, layer_output_list\n",
    "\n",
    "\n",
    "def parameter_initialization(x, layer_sizes):    # This function defined for random initialization of w and b.\n",
    "    length = len(x)\n",
    "    np.random.seed(0)\n",
    "    w_list1 = [np.random.randn(layer_sizes[0], length)]\n",
    "    w_list2 = [np.random.randn(next_layer, prev_layer) for prev_layer, next_layer in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
    "    w_list = w_list1 + w_list2\n",
    "    \n",
    "    b_list = [np.random.randn(layer, 1) for layer in layer_sizes]\n",
    "    return w_list, b_list     # returning randomly initialized w's and b's.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0bd54",
   "metadata": {},
   "source": [
    "# Extracting data from csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8f0de8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------The design matrix is :-------------------------------\n",
      "[[ 1.52813118  1.63635356]\n",
      " [ 0.43543038  1.1213705 ]\n",
      " [ 0.60378254  1.12762354]\n",
      " [-0.90367264 -0.71211216]\n",
      " [ 0.87514262  1.52022555]\n",
      " [ 0.51393422  1.46260819]\n",
      " [-1.06022653 -0.72863807]\n",
      " [-0.92772295 -0.25697968]\n",
      " [-1.11513384 -0.23866718]\n",
      " [ 0.90327694  0.71894227]\n",
      " [-0.99125206 -0.84119291]\n",
      " [ 0.97860433  1.33665396]\n",
      " [ 0.08874292  0.93109921]\n",
      " [ 0.65778229  1.36166615]\n",
      " [-0.45669993 -0.99707243]\n",
      " [-0.77797575 -0.84476608]\n",
      " [-0.42039758 -1.92698982]\n",
      " [-1.03163843 -1.71393958]\n",
      " [-0.84558888 -1.4240662 ]\n",
      " [-1.10106668 -0.44323114]\n",
      " [ 0.77531115  1.11065099]\n",
      " [ 0.76850446  0.54921671]\n",
      " [-0.30196115 -0.67638046]\n",
      " [-0.95177326 -0.54327989]\n",
      " [ 0.71949629  1.60821485]\n",
      " [-0.99578986 -0.70987892]\n",
      " [ 0.46038825  0.99898944]\n",
      " [ 1.26720803  0.25800339]\n",
      " [-1.87339923 -1.20744279]\n",
      " [-1.39738463 -0.75722342]\n",
      " [-1.52716554 -0.90729655]\n",
      " [ 0.21262469  0.94807177]\n",
      " [ 1.88344046  1.17050158]\n",
      " [ 0.73628612  0.62603986]\n",
      " [-0.18034827 -0.70228594]\n",
      " [ 0.85018475  1.75784133]\n",
      " [ 1.00855377  0.92529281]\n",
      " [ 0.69862243  1.05526686]\n",
      " [-0.51069968 -1.13061965]\n",
      " [ 0.51348044  0.95521811]\n",
      " [ 0.94865488  1.29198934]\n",
      " [ 1.57577802  1.04276076]\n",
      " [-1.38195613 -0.75231031]\n",
      " [ 0.98767991  1.20087352]\n",
      " [-0.53248109 -0.53970672]\n",
      " [-1.08836086 -0.8653118 ]\n",
      " [-1.07747015 -1.11096721]\n",
      " [ 0.54660633  1.22856558]\n",
      " [-1.42733407 -1.24898089]\n",
      " [-1.43731722 -1.18019737]\n",
      " [-0.26928903 -0.43742474]\n",
      " [-1.04706693 -0.52898721]\n",
      " [-0.72624489 -0.62233627]\n",
      " [-1.36153606 -0.32978301]\n",
      " [ 0.90599962  1.3031555 ]\n",
      " [-0.12544096  0.59432798]\n",
      " [ 0.77258848  0.42058261]\n",
      " [ 1.18779663  0.40227011]\n",
      " [-1.1623269  -0.7599033 ]\n",
      " [ 1.03033518  0.94271202]\n",
      " [ 0.50395107  1.25983082]\n",
      " [-1.5435016  -1.71438623]\n",
      " [ 0.93004993  0.91903977]\n",
      " [ 1.14786404  1.66672551]\n",
      " [ 0.61694214  0.68410387]\n",
      " [-1.11876408 -0.54953294]\n",
      " [ 1.29035078  1.04142083]\n",
      " [ 0.48761501  0.78951237]\n",
      " [-1.24990632 -0.72953136]\n",
      " [-0.71716931 -0.92203587]\n",
      " [ 1.58712251  1.12896348]\n",
      " [-1.21496531 -0.45261071]\n",
      " [ 0.7058829   0.46524723]\n",
      " [ 0.87423506  0.67740417]\n",
      " [-0.98126892 -1.30749154]\n",
      " [-0.85693336 -0.21588823]\n",
      " [-0.45715371 -0.44903754]\n",
      " [-1.33884709 -1.21994889]\n",
      " [-0.8451351  -1.4008406 ]\n",
      " [-1.21178886  0.24862382]\n",
      " [ 0.96499094  0.87750167]\n",
      " [ 0.60741277  1.02042845]\n",
      " [-0.78478244 -1.37270189]\n",
      " [ 0.0560708  -1.48793661]\n",
      " [ 1.29806503  1.28260977]\n",
      " [ 0.57474066  0.93422574]\n",
      " [-1.00758812 -0.96044744]\n",
      " [-0.26747392 -0.47315644]\n",
      " [ 1.13243554  1.0150687 ]\n",
      " [ 1.75638222  1.02846809]\n",
      " [ 0.21852382  1.16826835]\n",
      " [-0.18034827  0.95164494]\n",
      " [-1.05024339 -1.23960132]\n",
      " [ 0.73038699  0.71938892]\n",
      " [-0.23752448 -0.38114732]\n",
      " [ 0.23304477  0.81586449]\n",
      " [ 1.48093813  1.20801986]\n",
      " [ 0.58381624  0.88822118]\n",
      " [-1.8035172  -0.77553592]\n",
      " [-1.25671302 -1.29543209]\n",
      " [-1.17594028 -1.35885585]\n",
      " [ 1.10157854  0.06683882]\n",
      " [ 0.9658985   0.48400637]\n",
      " [-0.69448034 -0.85995205]\n",
      " [ 0.72539542  0.82971053]\n",
      " [-0.42130513 -0.66700089]\n",
      " [ 0.71178204  1.02310833]\n",
      " [-0.39407837 -1.39369426]\n",
      " [-0.62232941 -0.16899038]\n",
      " [-1.16368824 -1.61210425]\n",
      " [-0.74530363 -0.74337739]\n",
      " [-0.55698518 -1.43835888]\n",
      " [ 0.97951188  0.73323495]\n",
      " [-1.30980521 -0.87513802]\n",
      " [-0.45896882 -0.70183929]\n",
      " [-1.15642777 -0.71479203]\n",
      " [ 0.14773424  1.11869062]\n",
      " [ 2.00959113  1.49789324]\n",
      " [-0.22481865  0.39959024]\n",
      " [-0.44762434 -0.94660141]\n",
      " [ 0.26344799  1.43759601]\n",
      " [-0.66952247 -0.72640483]\n",
      " [ 0.6818326  -0.12164588]\n",
      " [ 0.83929405  0.88196813]\n",
      " [-0.19804567 -1.3302705 ]\n",
      " [ 1.06391485  0.49159935]\n",
      " [-0.82335369 -0.74605727]\n",
      " [-0.71172395 -0.96714714]\n",
      " [ 1.56715621  0.68455051]\n",
      " [ 0.8910249   1.01283547]\n",
      " [-0.66044688 -1.11588032]\n",
      " [ 0.11687724  2.3956521 ]\n",
      " [-1.09698267 -0.97831329]\n",
      " [-1.46091375 -0.1953425 ]\n",
      " [ 1.14741026  1.4675213 ]\n",
      " [ 0.81751264  0.68008405]\n",
      " [-1.12557077 -1.02521114]\n",
      " [ 0.44269085  0.65551851]\n",
      " [ 1.64384493  0.91993306]\n",
      " [ 1.228183    0.72742855]\n",
      " [-1.47135067 -0.26367937]\n",
      " [-0.40859931 -0.98233311]\n",
      " [ 0.48035454  0.60370755]\n",
      " [ 0.68228637  0.38261768]\n",
      " [ 0.67457213  0.3567122 ]\n",
      " [ 1.01399912  1.04901381]\n",
      " [-1.20725106 -2.04311783]\n",
      " [ 0.205818    1.10127142]\n",
      " [-0.57468257 -1.04039711]\n",
      " [ 0.55114413  1.31566159]\n",
      " [-0.507977   -0.87469137]\n",
      " [-1.13237746 -0.4602037 ]\n",
      " [-0.71353907 -1.73091214]\n",
      " [-0.85920226 -0.80322798]\n",
      " [-1.24945255 -1.29319886]\n",
      " [ 1.11020035  0.3866375 ]\n",
      " [ 0.56566507  1.03740101]\n",
      " [-1.0874533  -0.61161676]\n",
      " [ 0.63463954 -0.55131952]\n",
      " [ 1.77997875  1.42821644]\n",
      " [ 0.90191561  0.34286617]\n",
      " [-0.81881589 -1.09265472]\n",
      " [-1.25535168 -0.73801764]\n",
      " [ 0.0252138   1.54836426]\n",
      " [-0.86283249 -0.72104508]\n",
      " [ 0.54887523  1.06955954]\n",
      " [-0.84831155 -0.39588665]\n",
      " [-1.4223425  -1.18957694]\n",
      " [ 0.82749578  0.74484775]\n",
      " [ 1.27900629  1.05482021]\n",
      " [-0.72125332 -0.90640325]\n",
      " [-0.46985953 -0.91086971]\n",
      " [ 1.40334185  0.61889352]\n",
      " [ 1.17009923  1.45456856]\n",
      " [-0.97400845 -0.41107262]\n",
      " [-1.23629294 -0.57409848]\n",
      " [ 0.77394981  0.1508083 ]\n",
      " [ 0.87151239  1.31878812]\n",
      " [ 0.60605144  0.64881882]\n",
      " [-1.60385426 -0.97518677]\n",
      " [-0.39135569 -1.69160727]\n",
      " [ 1.15784719  0.48668625]\n",
      " [-0.8274377  -0.35702843]\n",
      " [-0.34416264 -1.04173705]\n",
      " [-1.16822603 -1.5594    ]\n",
      " [-0.67133759 -0.86084534]\n",
      " [ 0.53889208 -0.47806955]\n",
      " [-0.83016038 -1.53438781]\n",
      " [-0.54790959 -0.90461667]\n",
      " [ 0.91825166  0.68008405]\n",
      " [-0.12135695 -0.42759853]\n",
      " [ 0.93821796  1.39739785]\n",
      " [ 0.84020161  0.73144836]\n",
      " [ 1.10838523  0.73010842]\n",
      " [-0.99170584 -1.25434064]\n",
      " [ 0.59289183  0.62425328]\n",
      " [-0.75347166 -1.18645042]\n",
      " [-1.47044311 -1.1359794 ]\n",
      " [ 1.07344422  1.02534156]\n",
      " [-2.20828842 -1.04307699]\n",
      " [-0.16174332 -1.46515765]\n",
      " [ 1.01626802  0.75288738]\n",
      " [-1.00441167 -1.04441693]\n",
      " [-1.63698016 -0.43742474]\n",
      " [-1.46000619 -1.64783594]\n",
      " [ 1.10657012  0.71804898]\n",
      " [-1.63743394 -0.95196117]\n",
      " [-0.7634548  -0.42625859]\n",
      " [ 2.01957428  1.09189185]\n",
      " [ 0.16724675  0.53447739]\n",
      " [-0.77979086 -0.55757257]\n",
      " [-1.09335243 -0.35122203]\n",
      " [-0.99170584 -1.06898247]\n",
      " [ 1.50317332  0.71760233]\n",
      " [ 0.9041845   0.13070922]\n",
      " [ 0.83929405  1.0441007 ]\n",
      " [-0.57059856 -0.61429664]\n",
      " [ 0.15181825  1.37908535]\n",
      " [-0.69402656 -1.14446568]\n",
      " [ 0.58290869  1.32727439]\n",
      " [ 1.16465388  1.13789641]\n",
      " [-1.45728351 -0.60491707]\n",
      " [ 0.18857438  0.51080514]\n",
      " [-1.12466321 -0.76124324]\n",
      " [ 1.37429997  0.79219225]\n",
      " [ 1.23725859  0.87616173]\n",
      " [-0.66453089 -0.49057564]\n",
      " [ 1.20413269  0.97397725]\n",
      " [-0.62187563 -0.86888497]\n",
      " [-0.45443103 -0.19400256]\n",
      " [-0.76254725 -1.04486357]\n",
      " [ 1.39381248  1.48762038]\n",
      " [ 1.30169526  1.4027576 ]\n",
      " [-0.54972471 -1.52634818]\n",
      " [-0.21392795 -1.22754187]\n",
      " [ 0.68137882  0.46256735]\n",
      " [ 1.25631732 -0.08546754]\n",
      " [-0.78750511 -1.12168672]\n",
      " [-0.61733784 -0.71747191]\n",
      " [-1.11694896 -1.27845954]\n",
      " [-0.67950561 -0.64734846]\n",
      " [ 0.46628738  0.89000776]\n",
      " [ 0.47400163  0.88152149]\n",
      " [ 0.61104301  0.75199409]\n",
      " [ 1.14423381  1.27099697]\n",
      " [ 1.11836838  0.56976244]\n",
      " [-0.05692027  1.1678217 ]\n",
      " [-0.76935394 -1.26907997]\n",
      " [ 1.66789524  0.27676253]\n",
      " [-0.46486796 -1.07791539]\n",
      " [-0.45579237 -1.76217737]\n",
      " [ 0.5738331   0.78281268]\n",
      " [-0.96538664 -0.76526305]\n",
      " [-1.07383992 -0.28109857]\n",
      " [-0.92545405 -1.44818509]\n",
      " [ 0.43543038  0.9744239 ]\n",
      " [ 0.03519695  1.50101977]\n",
      " [ 1.4705012   1.47645422]\n",
      " [-1.14644462 -0.64645516]\n",
      " [ 0.79119343  0.51214508]\n",
      " [-1.50084634 -0.42715188]\n",
      " [ 0.76442045  0.51437831]\n",
      " [-0.67814428 -0.50888813]\n",
      " [-1.10333558 -0.05286236]\n",
      " [ 1.07934335  0.92395288]\n",
      " [-0.64864862 -0.79027524]\n",
      " [ 0.8029917   0.19502628]\n",
      " [-0.81064786 -1.03682394]\n",
      " [-0.74621119 -0.85414565]\n",
      " [ 1.0607384   0.2387976 ]\n",
      " [ 0.62647151  0.65194534]\n",
      " [ 0.8624368   1.38221188]\n",
      " [-0.78932023 -1.24094126]\n",
      " [ 0.67094189  1.05482021]\n",
      " [ 1.77997875  1.0499071 ]\n",
      " [-0.31648209 -0.6419887 ]\n",
      " [-1.33430929 -1.0180648 ]\n",
      " [ 1.35251855  1.00390255]\n",
      " [ 1.26811558  0.93556568]\n",
      " [ 1.36204792  1.1794345 ]\n",
      " [ 1.34435052  1.22454577]\n",
      " [ 0.9790581   1.14906256]\n",
      " [ 0.75489108  1.28082319]\n",
      " [-0.51977526 -0.61831645]\n",
      " [-0.68676609 -0.82734688]\n",
      " [-1.23175515 -0.87424473]\n",
      " [-0.06281941 -1.21324919]\n",
      " [-1.34202354 -1.13508611]\n",
      " [-0.78614377 -0.95374775]\n",
      " [ 0.70270645  0.28882198]\n",
      " [ 1.53539165  1.08385221]\n",
      " [-1.31797324 -0.94347489]\n",
      " [ 1.41423255  1.26965703]\n",
      " [-0.85375691 -0.89121728]\n",
      " [ 0.93549528  1.51665238]\n",
      " [-1.3429311   0.04271992]\n",
      " [ 0.71768117 -0.06536846]\n",
      " [ 1.70555893  0.61889352]\n",
      " [-0.55017848 -1.0122584 ]\n",
      " [-1.12602455 -1.11632697]\n",
      " [ 0.15136447  0.63407949]\n",
      " [ 0.83067224  0.5036588 ]\n",
      " [ 1.0276125   0.79085231]\n",
      " [ 1.03532675  0.49293929]\n",
      " [-1.30299852  0.21914517]\n",
      " [-1.56528301 -0.54327989]\n",
      " [ 1.04621746  0.67740417]\n",
      " [ 0.99176393  1.13789641]\n",
      " [ 1.16964545  0.75512061]\n",
      " [-1.13283124 -0.6661076 ]\n",
      " [-1.22676358 -1.17126445]\n",
      " [-0.4285656  -0.58660457]\n",
      " [-1.6778203  -0.6603012 ]\n",
      " [ 1.32483801  0.62827309]\n",
      " [-1.02982331 -1.1060541 ]\n",
      " [-1.27849443 -0.95508769]\n",
      " [ 0.50621997  1.59258224]\n",
      " [-1.41009045 -0.92739562]\n",
      " [ 1.40787964  0.30758112]\n",
      " [-0.41676734 -1.38476133]\n",
      " [-0.95857995 -1.41647321]\n",
      " [ 1.09023406  0.71268922]\n",
      " [-1.64605574 -1.311958  ]\n",
      " [ 0.58381624  0.88375472]\n",
      " [-1.19908303 -0.47806955]\n",
      " [-0.82789148 -0.18417635]\n",
      " [ 1.01808313  1.1968537 ]\n",
      " [ 1.04712502  0.94181872]\n",
      " [ 0.34512828  0.53715727]\n",
      " [ 0.6664041   0.00430835]\n",
      " [-0.39952372 -1.40530706]\n",
      " [-1.28757002 -0.68263351]\n",
      " [ 1.49046749  0.7801328 ]\n",
      " [-0.04739091  1.21650614]\n",
      " [ 1.36204792  0.64703223]\n",
      " [-0.42493537 -2.04579771]\n",
      " [-0.28154108 -0.82243377]\n",
      " [-1.11331872 -0.41330585]\n",
      " [-0.68495097 -0.2833318 ]\n",
      " [-0.96720176 -0.53390032]\n",
      " [ 1.03487297  1.45054875]\n",
      " [-1.067487   -1.80818193]\n",
      " [ 1.47458521  0.91323337]\n",
      " [-0.75755567 -1.7885295 ]\n",
      " [ 0.79709256  1.41258382]\n",
      " [-0.95494971 -1.23424156]\n",
      " [-0.16537355 -0.55221282]\n",
      " [ 0.85835278  0.99586291]\n",
      " [ 0.70951314  0.61710694]\n",
      " [ 0.96181449  0.72966178]\n",
      " [-1.2240409  -1.09310136]\n",
      " [ 0.44949754  0.76584012]\n",
      " [ 0.23349854  0.49517252]\n",
      " [ 0.32289309  1.41079723]\n",
      " [-1.0543274  -1.19136353]\n",
      " [ 0.71495849  0.46748046]\n",
      " [-1.03663001 -1.0654093 ]\n",
      " [-1.18229319 -1.52098842]\n",
      " [ 1.03759565  0.93824555]\n",
      " [-0.99034451 -1.43523235]\n",
      " [ 1.23226701  1.16603512]\n",
      " [-1.03799134 -0.80501457]\n",
      " [-0.37592719 -0.88317765]\n",
      " [-0.29606202 -1.46203113]\n",
      " [ 0.84110917  1.08965862]\n",
      " [-0.01381123  1.30806861]\n",
      " [ 1.00809999  1.09948483]\n",
      " [ 2.24419508  1.71942976]\n",
      " [-2.21282622 -0.53568691]\n",
      " [-0.60417823 -1.04352364]\n",
      " [-0.57422879 -1.15965165]\n",
      " [-1.05841142 -1.26059369]\n",
      " [ 0.89420136  0.75914043]\n",
      " [ 0.95863803  1.11288422]\n",
      " [-0.7085475  -0.72283166]\n",
      " [ 0.2389439   1.35853963]\n",
      " [ 1.58984518  0.16465434]\n",
      " [ 0.29022097  0.5219713 ]\n",
      " [-0.26747392 -0.27082571]\n",
      " [ 0.17995258  1.46528807]\n",
      " [-1.06612567 -0.69558625]\n",
      " [-0.26520502 -1.47766374]\n",
      " [-1.02846198 -1.32401745]\n",
      " [ 0.29929656  1.25625765]\n",
      " [-0.723976   -1.77245023]\n",
      " [ 1.15149428  0.04004005]\n",
      " [ 1.59483676  0.48311308]\n",
      " [ 0.24302791  0.97129737]\n",
      " [ 0.58109357  0.66043162]\n",
      " [ 1.55762684  1.23481863]\n",
      " [-1.21995688 -1.24496107]\n",
      " [-0.7943118  -1.00868523]\n",
      " [ 0.78121028  1.10752446]\n",
      " [-1.53170333 -1.21012267]\n",
      " [ 1.05393171  0.7743264 ]\n",
      " [-1.20588972 -1.56743963]\n",
      " [ 0.67774858  1.31387501]\n",
      " [-1.12693211 -0.41955889]\n",
      " [ 0.89465514  0.36966494]\n",
      " [-0.88461391 -0.75677678]\n",
      " [ 1.05302415  0.74127458]\n",
      " [ 0.60786655  0.80648492]\n",
      " [-1.27758687 -0.99439255]\n",
      " [-0.35414578 -0.30298424]\n",
      " [ 1.09295674  0.92975928]\n",
      " [-0.04421445 -0.46645675]\n",
      " [ 0.40048937 -0.88764411]\n",
      " [-1.17004115 -1.17439097]\n",
      " [ 1.18008238  1.30449544]\n",
      " [ 1.55218149  0.98826993]\n",
      " [ 0.85744522  0.21780523]\n",
      " [ 0.69181574  0.85784924]\n",
      " [ 0.64553024  0.68008405]\n",
      " [-1.0103108  -0.47494302]\n",
      " [ 0.03383561  1.21829272]\n",
      " [-1.43459454 -0.40437292]\n",
      " [ 1.1619312   0.68767704]\n",
      " [-1.09289865 -1.21458913]\n",
      " [-1.07928527 -0.24938669]\n",
      " [-0.60690091 -1.0828285 ]\n",
      " [ 1.20776292  0.71045599]\n",
      " [ 0.82431933  0.49874569]\n",
      " [ 0.84156295  1.33665396]\n",
      " [-0.88370635 -0.43295828]\n",
      " [-1.21315019 -0.79027524]\n",
      " [-1.14054549 -0.74695056]\n",
      " [ 1.80039883  1.72880933]\n",
      " [-0.58965729 -0.74471733]\n",
      " [ 0.58835404  0.9860367 ]\n",
      " [ 1.35660257  0.45095455]\n",
      " [-1.47452713 -0.99126603]\n",
      " [-1.43414076 -0.84878589]\n",
      " [-1.02755442 -1.035484  ]\n",
      " [ 0.84519318  1.19640706]\n",
      " [ 0.90826852  0.92841934]\n",
      " [ 0.84292428  1.99545711]\n",
      " [ 1.20095623  1.05973332]\n",
      " [-0.26293612 -0.57856494]\n",
      " [ 0.78121028  0.3567122 ]\n",
      " [ 0.62102616  0.44112833]\n",
      " [-0.19804567 -1.41647321]\n",
      " [ 0.71132826  1.39025151]\n",
      " [-1.24037696 -1.96272152]\n",
      " [ 1.72915546  0.65909168]\n",
      " [-0.5565314  -1.24317449]\n",
      " [ 0.73583234  0.66489808]\n",
      " [ 1.16102365  1.4733277 ]\n",
      " [ 1.35024966  0.93467238]\n",
      " [-0.67723672 -0.82511364]\n",
      " [-0.7657237  -1.80058895]\n",
      " [-0.86147116 -1.11007392]\n",
      " [-0.91728602 -0.37578757]\n",
      " [-1.39738463 -0.39320677]\n",
      " [ 1.27129204  1.21829272]\n",
      " [ 0.99584794  0.80067852]\n",
      " [-0.77570685 -0.05643553]\n",
      " [ 0.53163161  1.17988115]\n",
      " [ 1.043041    0.9386922 ]\n",
      " [ 1.22319142  2.01600283]\n",
      " [-1.20498216 -0.44367779]\n",
      " [ 0.96771362  1.54836426]\n",
      " [-0.99170584 -0.51380124]\n",
      " [ 1.18915797  0.97263731]\n",
      " [-1.18138563 -0.45395065]\n",
      " [-1.18728477 -0.46824333]\n",
      " [ 1.46777852  0.61666029]\n",
      " [ 1.58803006  1.66583221]\n",
      " [ 1.43873664  0.63854595]\n",
      " [-0.53293487 -0.73265788]\n",
      " [ 0.68092504  0.71358252]\n",
      " [-0.99805876 -0.90729655]\n",
      " [ 0.8315798   0.36162531]\n",
      " [-0.49073338 -0.50978143]\n",
      " [-0.06690342 -1.3061516 ]\n",
      " [-0.56061541 -0.64958169]\n",
      " [ 0.01341553 -0.62635609]\n",
      " [-0.88642902 -0.50486832]\n",
      " [ 0.65687473  1.13521653]\n",
      " [-0.94042877 -0.80769444]\n",
      " [-1.42914919 -0.96893372]\n",
      " [ 1.1465027   0.85338278]\n",
      " [-0.67133759 -1.50714239]\n",
      " [-1.44775414 -0.81930724]\n",
      " [ 0.92732725  1.31208842]\n",
      " [-0.74394229 -1.10739404]\n",
      " [-0.25885211 -1.42897931]\n",
      " [ 1.79177702  0.06639217]\n",
      " [ 1.67379437  0.4572076 ]\n",
      " [ 0.78075651  0.98291017]\n",
      " [ 0.13502841  0.73770141]\n",
      " [-0.95994129 -0.72908471]\n",
      " [ 1.27719117  1.26608386]\n",
      " [ 0.65324449  0.51482496]\n",
      " [-1.17503272 -0.45752382]\n",
      " [-1.01076458 -0.37444763]\n",
      " [-1.68961857 -1.05692302]\n",
      " [ 0.95863803  0.12802935]\n",
      " [ 1.15784719  1.00792236]\n",
      " [-0.66816113 -1.57592591]\n",
      " [-0.85284935 -1.39458755]]\n",
      "500 2\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Logistic_regression_ls.csv')    # reads the smarket csv file using pandas library.\n",
    "\n",
    "# print('The given data-set is:')\n",
    "# print(data)\n",
    "\n",
    "# extracting the ground truth label column from the data set.\n",
    "y = data[['label']]\n",
    "y = y.values\n",
    "\n",
    "# extracting the features from the adta set.\n",
    "features = data[data.columns[0 : (len(data.columns)-1)]]\n",
    "features = features.values\n",
    "\n",
    "r, c = np.shape(features)\n",
    "\n",
    "for i in range(c):     # normalizing the features.\n",
    "    features[:,i] = (features[:,i] - features[:,i].mean())/features[:,i].std()\n",
    "    \n",
    "\n",
    "X = features\n",
    "\n",
    "print('--------------------------The design matrix is :-------------------------------')\n",
    "print(X)\n",
    "\n",
    "r, c = np.shape(X)\n",
    "print(r, c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feb8659",
   "metadata": {},
   "source": [
    "# The activation function in two hidden layers is sigmoid and output layer is also sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3f40ed71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial weight matrix are:\n",
      "[array([[ 1.76405235,  0.40015721],\n",
      "       [ 0.97873798,  2.2408932 ],\n",
      "       [ 1.86755799, -0.97727788],\n",
      "       [ 0.95008842, -0.15135721],\n",
      "       [-0.10321885,  0.4105985 ]]), array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323],\n",
      "       [ 0.33367433,  1.49407907, -0.20515826,  0.3130677 , -0.85409574],\n",
      "       [-2.55298982,  0.6536186 ,  0.8644362 , -0.74216502,  2.26975462],\n",
      "       [-1.45436567,  0.04575852, -0.18718385,  1.53277921,  1.46935877],\n",
      "       [ 0.15494743,  0.37816252, -0.88778575, -1.98079647, -0.34791215]]), array([[ 0.15634897,  1.23029068,  1.20237985, -0.38732682, -0.30230275]])]\n",
      "\n",
      "The initial bias vector is:\n",
      "[array([[-1.04855297],\n",
      "       [-1.42001794],\n",
      "       [-1.70627019],\n",
      "       [ 1.9507754 ],\n",
      "       [-0.50965218]]), array([[-0.4380743 ],\n",
      "       [-1.25279536],\n",
      "       [ 0.77749036],\n",
      "       [-1.61389785],\n",
      "       [-0.21274028]]), array([[-0.89546656]])]\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [5, 5, 1]  # this list contains the number of neurons has to be in each specified layer.\n",
    "\n",
    "w_list, b_list = parameter_initialization(X[0], layer_sizes)\n",
    "print('The initial weight matrix are:')\n",
    "print(w_list)\n",
    "print('\\nThe initial bias vector is:')\n",
    "print(b_list)\n",
    "\n",
    "n_layer = 3          # number of layers.\n",
    "f_list = [sigmoid, sigmoid, sigmoid]  # activation function of each specified layer.\n",
    "\n",
    "num_row , num_col = np.shape(X)\n",
    "y_pred = np.zeros((num_row, 1))\n",
    "for j in range(num_row):\n",
    "    x = X[j]\n",
    "    x = x.reshape((len(x), 1))\n",
    "    activation_list, layer_output_list = forward_prop(x, n_layer, f_list, w_list, b_list) # calling forward propagation algo.\n",
    "    y_pred[j][0] = layer_output_list[n_layer-1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7eacb82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = np.zeros((y_pred.shape[0], y_pred.shape[1]), dtype = int)\n",
    "for i in range(y_pred.shape[0]):     # predicting label using thereshold value 0.5\n",
    "    if(y_pred[i][0] > 0.5):\n",
    "        y_pred_label[i][0] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "063f3161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 0 250 1\n",
      "The precision is: 0.498997994991988\n",
      "The recall is: 0.995999996016\n",
      "The f1 score is: 0.6648860688379642\n",
      "The accuracy is: 0.498\n",
      "The cross entropy error is: 0.6437290035888877\n",
      "The mse error is: 0.2255706668774952\n"
     ]
    }
   ],
   "source": [
    "# evaluation metric and loss functions.\n",
    "eps = 10e-7\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(X.shape[0]):\n",
    "    if((y[i][0] == 1) and (y_pred_label[i][0] == 1)):\n",
    "        TP += 1\n",
    "    if((y[i][0] == 0) and (y_pred_label[i][0] == 0)):\n",
    "        TN += 1    \n",
    "    if((y[i][0] == 0) and (y_pred_label[i][0] == 1)):\n",
    "        FP += 1\n",
    "    if((y[i][0] == 1) and (y_pred_label[i][0] == 0)):  \n",
    "        FN += 1\n",
    "print(TP, TN, FP, FN)\n",
    "P = TP/(TP+FP+eps)\n",
    "R = TP/(TP+FN+eps)\n",
    "print('The precision is:', P)\n",
    "print('The recall is:', R)\n",
    "\n",
    "F1 = 2*((P*R)/(P+R+eps))\n",
    "print('The f1 score is:', F1)\n",
    "\n",
    "Acc = (TP + TN)/(TP + FP + FN + TN)\n",
    "print('The accuracy is:', Acc)\n",
    "\n",
    "cross_entropy_error = cross_entropy(y, y_pred)\n",
    "print(f'The cross entropy error is: {cross_entropy_error}')\n",
    "\n",
    "mse_error = MSE(y, y_pred)\n",
    "print(f'The mse error is: {mse_error}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a006938",
   "metadata": {},
   "source": [
    "# The activation function in two hidden layers is ReLU and output layer is sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f7e3da31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial weight matrix are:\n",
      "[array([[ 1.76405235,  0.40015721],\n",
      "       [ 0.97873798,  2.2408932 ],\n",
      "       [ 1.86755799, -0.97727788],\n",
      "       [ 0.95008842, -0.15135721],\n",
      "       [-0.10321885,  0.4105985 ]]), array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323],\n",
      "       [ 0.33367433,  1.49407907, -0.20515826,  0.3130677 , -0.85409574],\n",
      "       [-2.55298982,  0.6536186 ,  0.8644362 , -0.74216502,  2.26975462],\n",
      "       [-1.45436567,  0.04575852, -0.18718385,  1.53277921,  1.46935877],\n",
      "       [ 0.15494743,  0.37816252, -0.88778575, -1.98079647, -0.34791215]]), array([[ 0.15634897,  1.23029068,  1.20237985, -0.38732682, -0.30230275]])]\n",
      "\n",
      "The initial bias vector is:\n",
      "[array([[-1.04855297],\n",
      "       [-1.42001794],\n",
      "       [-1.70627019],\n",
      "       [ 1.9507754 ],\n",
      "       [-0.50965218]]), array([[-0.4380743 ],\n",
      "       [-1.25279536],\n",
      "       [ 0.77749036],\n",
      "       [-1.61389785],\n",
      "       [-0.21274028]]), array([[-0.89546656]])]\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [5, 5, 1] \n",
    "\n",
    "w_list, b_list = parameter_initialization(X[0], layer_sizes)\n",
    "print('The initial weight matrix are:')\n",
    "print(w_list)\n",
    "print('\\nThe initial bias vector is:')\n",
    "print(b_list)\n",
    "\n",
    "n_layer = 3\n",
    "f_list = [Relu, Relu, sigmoid]\n",
    "\n",
    "num_row , num_col = np.shape(X)\n",
    "y_pred = np.zeros((num_row, 1))\n",
    "for j in range(num_row):\n",
    "    x = X[j]\n",
    "    x = x.reshape((len(x), 1))\n",
    "    activation_list, layer_output_list = forward_prop(x, n_layer, f_list, w_list, b_list)\n",
    "    y_pred[j][0] = layer_output_list[n_layer-1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e872807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = np.zeros((y_pred.shape[0], y_pred.shape[1]), dtype = int)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if(y_pred[i][0] > 0.5):\n",
    "        y_pred_label[i][0] = 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9fbdfdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 248 2 68\n",
      "The precision is: 0.9891304347826086\n",
      "The recall is: 0.728\n",
      "The f1 score is: 0.8387091889828493\n",
      "The accuracy is: 0.86\n",
      "The cross entropy error is: 0.4097752974802999\n",
      "The mse error is: 0.1276213027348106\n"
     ]
    }
   ],
   "source": [
    "eps = 10e-7\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(X.shape[0]):\n",
    "    if((y[i][0] == 1) and (y_pred_label[i][0] == 1)):\n",
    "        TP += 1\n",
    "    if((y[i][0] == 0) and (y_pred_label[i][0] == 0)):\n",
    "        TN += 1    \n",
    "    if((y[i][0] == 0) and (y_pred_label[i][0] == 1)):\n",
    "        FP += 1\n",
    "    if((y[i][0] == 1) and (y_pred_label[i][0] == 0)):  \n",
    "        FN += 1\n",
    "print(TP, TN, FP, FN)\n",
    "P = TP/(TP+FP)\n",
    "R = TP/(TP+FN)\n",
    "print('The precision is:', P)\n",
    "print('The recall is:', R)\n",
    "\n",
    "F1 = 2*((P*R)/(P+R+eps))\n",
    "print('The f1 score is:', F1)\n",
    "\n",
    "Acc = (TP + TN)/(TP + FP + FN + TN)\n",
    "print('The accuracy is:', Acc)\n",
    "\n",
    "cross_entropy_error = cross_entropy(y, y_pred)\n",
    "print(f'The cross entropy error is: {cross_entropy_error}')\n",
    "\n",
    "mse_error = MSE(y, y_pred)\n",
    "print(f'The mse error is: {mse_error}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3324b",
   "metadata": {},
   "source": [
    "# The activation function in two hidden layers is Tanh and output layer is sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7095dd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial weight matrix are:\n",
      "[array([[ 1.76405235,  0.40015721],\n",
      "       [ 0.97873798,  2.2408932 ],\n",
      "       [ 1.86755799, -0.97727788],\n",
      "       [ 0.95008842, -0.15135721],\n",
      "       [-0.10321885,  0.4105985 ]]), array([[ 0.14404357,  1.45427351,  0.76103773,  0.12167502,  0.44386323],\n",
      "       [ 0.33367433,  1.49407907, -0.20515826,  0.3130677 , -0.85409574],\n",
      "       [-2.55298982,  0.6536186 ,  0.8644362 , -0.74216502,  2.26975462],\n",
      "       [-1.45436567,  0.04575852, -0.18718385,  1.53277921,  1.46935877],\n",
      "       [ 0.15494743,  0.37816252, -0.88778575, -1.98079647, -0.34791215]]), array([[ 0.15634897,  1.23029068,  1.20237985, -0.38732682, -0.30230275]])]\n",
      "\n",
      "The initial bias vector is:\n",
      "[array([[-1.04855297],\n",
      "       [-1.42001794],\n",
      "       [-1.70627019],\n",
      "       [ 1.9507754 ],\n",
      "       [-0.50965218]]), array([[-0.4380743 ],\n",
      "       [-1.25279536],\n",
      "       [ 0.77749036],\n",
      "       [-1.61389785],\n",
      "       [-0.21274028]]), array([[-0.89546656]])]\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [5, 5, 1] \n",
    "\n",
    "w_list, b_list = parameter_initialization(X[0], layer_sizes)\n",
    "print('The initial weight matrix are:')\n",
    "print(w_list)\n",
    "print('\\nThe initial bias vector is:')\n",
    "print(b_list)\n",
    "\n",
    "n_layer = 3\n",
    "f_list = [Tanh, Tanh, sigmoid]\n",
    "\n",
    "num_row , num_col = np.shape(X)\n",
    "y_pred = np.zeros((num_row, 1))\n",
    "for j in range(num_row):\n",
    "    x = X[j]\n",
    "    x = x.reshape((len(x), 1))\n",
    "    activation_list, layer_output_list = forward_prop(x, n_layer, f_list, w_list, b_list)\n",
    "    y_pred[j][0] = layer_output_list[n_layer-1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "867774f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = np.zeros((y_pred.shape[0], y_pred.shape[1]), dtype = int)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if(y_pred[i][0] > 0.5):\n",
    "        y_pred_label[i][0] = 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "22e95bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 250 0 237\n",
      "The precision is: 1.0\n",
      "The recall is: 0.052\n",
      "The f1 score is: 0.09885922161670949\n",
      "The accuracy is: 0.526\n",
      "The cross entropy error is: 0.620933664389128\n",
      "The mse error is: 0.2259516619633743\n"
     ]
    }
   ],
   "source": [
    "eps = 10e-7\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(X.shape[0]):\n",
    "    if((y[i][0] == 1) and (y_pred_label[i][0] == 1)):\n",
    "        TP += 1\n",
    "    if((y[i][0] == 0) and (y_pred_label[i][0] == 0)):\n",
    "        TN += 1    \n",
    "    if((y[i][0] == 0) and (y_pred_label[i][0] == 1)):\n",
    "        FP += 1\n",
    "    if((y[i][0] == 1) and (y_pred_label[i][0] == 0)):  \n",
    "        FN += 1\n",
    "print(TP, TN, FP, FN)\n",
    "P = TP/(TP+FP)\n",
    "R = TP/(TP+FN)\n",
    "print('The precision is:', P)\n",
    "print('The recall is:', R)\n",
    "\n",
    "F1 = 2*((P*R)/(P+R+eps))\n",
    "print('The f1 score is:', F1)\n",
    "\n",
    "Acc = (TP + TN)/(TP + FP + FN + TN)\n",
    "print('The accuracy is:', Acc)\n",
    "\n",
    "cross_entropy_error = cross_entropy(y, y_pred)\n",
    "print(f'The cross entropy error is: {cross_entropy_error}')\n",
    "\n",
    "mse_error = MSE(y, y_pred)\n",
    "print(f'The mse error is: {mse_error}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76cbd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d9dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a2ee47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
